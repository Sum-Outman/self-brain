#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çœŸå®Aç®¡ç†æ¨¡å‹è®­ç»ƒç³»ç»Ÿ - å®æ—¶æ•°æ®ç”Ÿæˆå’Œè®­ç»ƒ
"""

import torch
import torch.nn as nn
import numpy as np
import asyncio
import json
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import websockets
import threading
import queue
from collections import deque
import os
import sys

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from real_trainable_a_manager import RealTrainableAManager, ModelConfig, InteractiveAManager

class RealTimeDataGenerator:
    """å®æ—¶æ•°æ®ç”Ÿæˆå™¨ - æ¨¡æ‹ŸçœŸå®ç¯å¢ƒæ•°æ®"""
    
    def __init__(self):
        self.running = False
        self.data_queue = queue.Queue(maxsize=1000)
        self.emotion_history = deque(maxlen=1000)
        self.task_history = deque(maxlen=1000)
        
        # æ¨¡æ‹Ÿæ•°æ®æ¨¡æ¿
        self.task_templates = {
            'text': [
                "åˆ†æè¿™æ®µæ–‡æœ¬çš„æƒ…æ„Ÿè‰²å½©",
                "å°†è¿™æ®µæ–‡å­—ç¿»è¯‘æˆè‹±æ–‡",
                "æ€»ç»“è¿™ç¯‡æ–‡ç« çš„ä¸»è¦å†…å®¹",
                "æ£€æµ‹æ–‡æœ¬ä¸­çš„æ•æ„Ÿä¿¡æ¯",
                "ç”Ÿæˆä¸€æ®µå…³äºAIçš„è¯—æ­Œ"
            ],
            'audio': [
                "è¯†åˆ«è¿™æ®µè¯­éŸ³çš„å†…å®¹",
                "å°†è¯­éŸ³è½¬æ¢ä¸ºæ–‡å­—",
                "åˆ†æè¯´è¯äººçš„æƒ…æ„Ÿ",
                "æ£€æµ‹è¯­éŸ³ä¸­çš„å…³é”®è¯",
                "ç”Ÿæˆè¯­éŸ³å›å¤"
            ],
            'image': [
                "è¯†åˆ«å›¾ç‰‡ä¸­çš„ç‰©ä½“",
                "æ£€æµ‹äººè„¸å¹¶åˆ†æè¡¨æƒ…",
                "æå–å›¾ç‰‡ä¸­çš„æ–‡å­—",
                "åˆ¤æ–­å›¾ç‰‡çš„é£æ ¼",
                "ç”Ÿæˆå›¾ç‰‡æè¿°"
            ],
            'video': [
                "åˆ†æè§†é¢‘å†…å®¹",
                "æ£€æµ‹è§†é¢‘ä¸­çš„äººç‰©",
                "æå–è§†é¢‘å…³é”®å¸§",
                "è¯†åˆ«è§†é¢‘ä¸­çš„åŠ¨ä½œ",
                "ç”Ÿæˆè§†é¢‘æ‘˜è¦"
            ],
            'spatial': [
                "è®¡ç®—ç‰©ä½“çš„3Dä½ç½®",
                "åˆ†æç©ºé—´å…³ç³»",
                "æ£€æµ‹éšœç¢ç‰©",
                "è§„åˆ’è·¯å¾„",
                "æµ‹é‡è·ç¦»"
            ],
            'sensor': [
                "åˆ†æä¼ æ„Ÿå™¨æ•°æ®",
                "æ£€æµ‹å¼‚å¸¸è¯»æ•°",
                "é¢„æµ‹è®¾å¤‡çŠ¶æ€",
                "æ ¡å‡†ä¼ æ„Ÿå™¨",
                "æ•°æ®èåˆ"
            ],
            'control': [
                "ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½",
                "è°ƒæ•´å‚æ•°è®¾ç½®",
                "ç›‘æ§ç³»ç»ŸçŠ¶æ€",
                "æ•…éšœè¯Šæ–­",
                "èµ„æºåˆ†é…"
            ],
            'motion': [
                "è§„åˆ’è¿åŠ¨è½¨è¿¹",
                "æ§åˆ¶æœºæ¢°è‡‚",
                "å¹³è¡¡æ§åˆ¶",
                "æ­¥æ€è§„åˆ’",
                "ç¢°æ’é¿å…"
            ],
            'knowledge': [
                "æŸ¥è¯¢çŸ¥è¯†åº“",
                "æ¨ç†å› æœå…³ç³»",
                "éªŒè¯äº‹å®",
                "çŸ¥è¯†å›¾è°±æŸ¥è¯¢",
                "ä¸“å®¶å’¨è¯¢"
            ],
            'programming': [
                "ç”Ÿæˆä»£ç ç‰‡æ®µ",
                "è°ƒè¯•ç¨‹åº",
                "ä»£ç ä¼˜åŒ–",
                "ç®—æ³•è®¾è®¡",
                "APIæ–‡æ¡£"
            ]
        }
        
        # æƒ…æ„Ÿæ ‡ç­¾
        self.emotion_labels = [
            'joy', 'sadness', 'anger', 'fear', 
            'surprise', 'disgust', 'trust', 'anticipation'
        ]
        
        # æ¨¡å‹åç§°
        self.model_names = [
            'A_language', 'B_audio', 'C_image', 'D_video', 'E_spatial',
            'F_sensor', 'G_computer', 'H_motion', 'I_knowledge', 
            'J_controller', 'K_programming'
        ]
    
    def start_generation(self):
        """å¼€å§‹å®æ—¶æ•°æ®ç”Ÿæˆ"""
        self.running = True
        self.generation_thread = threading.Thread(target=self._generate_loop)
        self.generation_thread.daemon = True
        self.generation_thread.start()
        logging.info("å®æ—¶æ•°æ®ç”Ÿæˆå™¨å·²å¯åŠ¨")
    
    def stop_generation(self):
        """åœæ­¢æ•°æ®ç”Ÿæˆ"""
        self.running = False
        if hasattr(self, 'generation_thread'):
            self.generation_thread.join()
        logging.info("å®æ—¶æ•°æ®ç”Ÿæˆå™¨å·²åœæ­¢")
    
    def _generate_loop(self):
        """æ•°æ®ç”Ÿæˆä¸»å¾ªç¯"""
        while self.running:
            try:
                # ç”Ÿæˆä»»åŠ¡æ•°æ®
                task_data = self._generate_task_data()
                
                # ç”Ÿæˆæƒ…æ„Ÿæ•°æ®
                emotion_data = self._generate_emotion_data()
                
                # ç”Ÿæˆè®­ç»ƒæ ·æœ¬
                training_sample = self._generate_training_sample(task_data, emotion_data)
                
                # æ”¾å…¥é˜Ÿåˆ—
                if not self.data_queue.full():
                    self.data_queue.put(training_sample)
                
                # è®°å½•å†å²
                self.task_history.append(task_data)
                self.emotion_history.append(emotion_data)
                
                time.sleep(0.1)  # æ§åˆ¶ç”Ÿæˆé€Ÿåº¦
                
            except Exception as e:
                logging.error(f"æ•°æ®ç”Ÿæˆé”™è¯¯: {e}")
    
    def _generate_task_data(self) -> Dict:
        """ç”Ÿæˆä»»åŠ¡æ•°æ®"""
        task_type = np.random.choice(list(self.task_templates.keys()))
        description = np.random.choice(self.task_templates[task_type])
        
        # ç”Ÿæˆå¤æ‚åº¦è¯„åˆ†
        complexity = np.random.beta(2, 5)  # åå‘ä½å¤æ‚åº¦
        
        # ç”Ÿæˆé¢„æœŸå¤„ç†æ—¶é—´
        expected_time = np.random.exponential(2) + 0.5
        
        return {
            'type': task_type,
            'description': description,
            'complexity': float(complexity),
            'expected_time': float(expected_time),
            'timestamp': datetime.now().isoformat()
        }
    
    def _generate_emotion_data(self) -> Dict:
        """ç”Ÿæˆæƒ…æ„Ÿæ•°æ®"""
        # åŸºäºæ—¶é—´å˜åŒ–çš„æƒ…æ„Ÿ
        current_time = datetime.now()
        hour_factor = np.sin(2 * np.pi * current_time.hour / 24)
        
        # åŸºç¡€æƒ…æ„Ÿåˆ†å¸ƒ
        base_emotions = np.array([0.3, 0.1, 0.05, 0.05, 0.2, 0.05, 0.15, 0.1])
        
        # æ·»åŠ éšæœºæ³¢åŠ¨å’Œæ—¶é—´å½±å“
        noise = np.random.normal(0, 0.1, 8)
        time_influence = np.array([
            hour_factor * 0.1,  # joy
            -abs(hour_factor) * 0.05,  # sadness
            abs(hour_factor) * 0.03,  # anger
            0.02,  # fear
            0.05,  # surprise
            0.02,  # disgust
            0.03,  # trust
            0.04   # anticipation
        ])
        
        emotions = base_emotions + noise + time_influence
        emotions = np.clip(emotions, 0.01, 0.99)
        emotions = emotions / emotions.sum()
        
        return {
            'emotions': emotions.tolist(),
            'timestamp': current_time.isoformat(),
            'hour_factor': float(hour_factor)
        }
    
    def _generate_training_sample(self, task_data: Dict, emotion_data: Dict) -> Dict:
        """ç”Ÿæˆè®­ç»ƒæ ·æœ¬"""
        # æ¨¡æ‹Ÿè¾“å…¥ç‰¹å¾
        input_features = torch.randn(50, 768)
        
        # ç”Ÿæˆç›®æ ‡æ ‡ç­¾
        emotion_targets = torch.tensor(emotion_data['emotions'])
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©ç›®æ ‡æ¨¡å‹
        task_type_idx = list(self.task_templates.keys()).index(task_data['type'])
        model_targets = torch.zeros(11)
        model_targets[task_type_idx % 11] = 0.8  # ä¸»è¦æ¨¡å‹
        model_targets[(task_type_idx + 1) % 11] = 0.2  # è¾…åŠ©æ¨¡å‹
        
        # ç”Ÿæˆå…¶ä»–ç›®æ ‡
        importance_target = torch.tensor([task_data['complexity']])
        confidence_target = torch.tensor([0.8 + 0.2 * np.random.random()])
        
        return {
            'input': input_features,
            'emotion_target': emotion_targets,
            'model_target': model_targets,
            'importance_target': importance_target,
            'confidence_target': confidence_target,
            'metadata': {
                'task': task_data,
                'emotion': emotion_data
            }
        }

class RealTimeTrainer:
    """å®æ—¶è®­ç»ƒå™¨"""
    
    def __init__(self, model: RealTrainableAManager, data_generator: RealTimeDataGenerator):
        self.model = model
        self.data_generator = data_generator
        self.config = ModelConfig()
        
        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=self.config.learning_rate,
            weight_decay=1e-4
        )
        
        # æŸå¤±å‡½æ•°
        self.criterion_emotion = nn.BCELoss()
        self.criterion_model = nn.KLDivLoss(reduction='batchmean')
        self.criterion_regression = nn.MSELoss()
        
        # è®­ç»ƒçŠ¶æ€
        self.training = False
        self.metrics = {
            'total_loss': deque(maxlen=100),
            'emotion_loss': deque(maxlen=100),
            'model_loss': deque(maxlen=100),
            'confidence_loss': deque(maxlen=100)
        }
        
        # WebSocketæœåŠ¡å™¨
        self.clients = set()
        self.websocket_thread = None
    
    def start_training(self):
        """å¼€å§‹å®æ—¶è®­ç»ƒ"""
        self.training = True
        self.data_generator.start_generation()
        
        # å¯åŠ¨è®­ç»ƒçº¿ç¨‹
        training_thread = threading.Thread(target=self._training_loop)
        training_thread.daemon = True
        training_thread.start()
        
        # å¯åŠ¨WebSocketæœåŠ¡å™¨
        self.websocket_thread = threading.Thread(target=self._start_websocket_server)
        self.websocket_thread.daemon = True
        self.websocket_thread.start()
        
        logging.info("å®æ—¶è®­ç»ƒç³»ç»Ÿå·²å¯åŠ¨")
    
    def stop_training(self):
        """åœæ­¢è®­ç»ƒ"""
        self.training = False
        self.data_generator.stop_generation()
        logging.info("å®æ—¶è®­ç»ƒç³»ç»Ÿå·²åœæ­¢")
    
    def _training_loop(self):
        """è®­ç»ƒä¸»å¾ªç¯"""
        batch_size = 16
        accumulation_steps = 4
        
        while self.training:
            try:
                # æ”¶é›†æ‰¹æ¬¡æ•°æ®
                batch_data = []
                for _ in range(batch_size):
                    if not self.data_generator.data_queue.empty():
                        sample = self.data_generator.data_queue.get()
                        batch_data.append(sample)
                
                if len(batch_data) == 0:
                    time.sleep(0.1)
                    continue
                
                # å‡†å¤‡è®­ç»ƒæ•°æ®
                inputs = torch.stack([sample['input'] for sample in batch_data])
                emotion_targets = torch.stack([sample['emotion_target'] for sample in batch_data])
                model_targets = torch.stack([sample['model_target'] for sample in batch_data])
                importance_targets = torch.stack([sample['importance_target'] for sample in batch_data])
                confidence_targets = torch.stack([sample['confidence_target'] for sample in batch_data])
                
                # è½¬ç§»åˆ°è®¾å¤‡
                inputs = inputs.to(self.config.device)
                emotion_targets = emotion_targets.to(self.config.device)
                model_targets = model_targets.to(self.config.device)
                importance_targets = importance_targets.to(self.config.device)
                confidence_targets = confidence_targets.to(self.config.device)
                
                # å‰å‘ä¼ æ’­
                self.model.train()
                outputs = self.model(inputs)
                
                # è®¡ç®—æŸå¤±
                emotion_loss = self.criterion_emotion(outputs['emotions'], emotion_targets)
                model_loss = self.criterion_model(
                    F.log_softmax(outputs['model_weights'], dim=-1),
                    model_targets
                )
                importance_loss = self.criterion_regression(
                    outputs['task_embedding'].mean(dim=1), 
                    importance_targets.squeeze()
                )
                confidence_loss = self.criterion_regression(outputs['confidence'], confidence_targets)
                
                # æ€»æŸå¤±
                total_loss = (
                    emotion_loss * 0.3 +
                    model_loss * 0.4 +
                    importance_loss * 0.2 +
                    confidence_loss * 0.1
                )
                
                # åå‘ä¼ æ’­
                total_loss.backward()
                
                # æ¢¯åº¦ç´¯ç§¯
                if len(batch_data) >= batch_size:
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                    self.optimizer.step()
                    self.optimizer.zero_grad()
                
                # è®°å½•æŒ‡æ ‡
                self.metrics['total_loss'].append(total_loss.item())
                self.metrics['emotion_loss'].append(emotion_loss.item())
                self.metrics['model_loss'].append(model_loss.item())
                self.metrics['confidence_loss'].append(confidence_loss.item())
                
                # å®šæœŸä¿å­˜æ¨¡å‹
                if len(self.metrics['total_loss']) % 100 == 0:
                    self.model.save_model('a_manager_realtime_latest.pth')
                
                # å¹¿æ’­è®­ç»ƒçŠ¶æ€
                asyncio.create_task(self.broadcast_training_status())
                
            except Exception as e:
                logging.error(f"è®­ç»ƒå¾ªç¯é”™è¯¯: {e}")
                time.sleep(1)
    
    async def broadcast_training_status(self):
        """å¹¿æ’­è®­ç»ƒçŠ¶æ€"""
        if not self.clients:
            return
        
        status = {
            'type': 'training_status',
            'timestamp': datetime.now().isoformat(),
            'metrics': {
                'total_loss': np.mean(list(self.metrics['total_loss'])) if self.metrics['total_loss'] else 0,
                'emotion_loss': np.mean(list(self.metrics['emotion_loss'])) if self.metrics['emotion_loss'] else 0,
                'model_loss': np.mean(list(self.metrics['model_loss'])) if self.metrics['model_loss'] else 0,
                'confidence_loss': np.mean(list(self.metrics['confidence_loss'])) if self.metrics['confidence_loss'] else 0
            },
            'queue_size': self.data_generator.data_queue.qsize(),
            'training': self.training
        }
        
        message = json.dumps(status)
        await asyncio.gather(
            *[client.send(message) for client in self.clients],
            return_exceptions=True
        )
    
    async def handle_websocket_client(self, websocket, path):
        """å¤„ç†WebSocketå®¢æˆ·ç«¯"""
        self.clients.add(websocket)
        logging.info(f"å®¢æˆ·ç«¯è¿æ¥: {websocket.remote_address}")
        
        try:
            async for message in websocket:
                data = json.loads(message)
                
                if data['type'] == 'get_status':
                    await self.broadcast_training_status()
                
                elif data['type'] == 'process_task':
                    # å¤„ç†ä»»åŠ¡è¯·æ±‚
                    interactive = InteractiveAManager()
                    result = interactive.process_task(
                        data['task_type'], 
                        data['description']
                    )
                    await websocket.send(json.dumps({
                        'type': 'task_result',
                        'result': result
                    }))
        
        except websockets.exceptions.ConnectionClosed:
            pass
        finally:
            self.clients.discard(websocket)
            logging.info(f"å®¢æˆ·ç«¯æ–­å¼€: {websocket.remote_address}")
    
    def _start_websocket_server(self):
        """å¯åŠ¨WebSocketæœåŠ¡å™¨"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        start_server = websockets.serve(
            self.handle_websocket_client,
            'localhost',
            8766
        )
        
        loop.run_until_complete(start_server)
        logging.info("WebSocketæœåŠ¡å™¨å·²å¯åŠ¨: ws://localhost:8766")
        loop.run_forever()

class AManagerDashboard:
    """Aç®¡ç†æ¨¡å‹è®­ç»ƒä»ªè¡¨æ¿"""
    
    def __init__(self):
        self.config = ModelConfig()
        self.model = RealTrainableAManager(self.config)
        self.data_generator = RealTimeDataGenerator()
        self.trainer = RealTimeTrainer(self.model, self.data_generator)
    
    def start(self):
        """å¯åŠ¨å®Œæ•´ç³»ç»Ÿ"""
        print("ğŸ¯ å¯åŠ¨Aç®¡ç†æ¨¡å‹å®æ—¶è®­ç»ƒç³»ç»Ÿ")
        print("=" * 50)
        
        # æ£€æŸ¥è®¾å¤‡
        print(f"è®¾å¤‡: {self.config.device}")
        print(f"æ¨¡å‹å‚æ•°: {sum(p.numel() for p in self.model.parameters()):,}")
        
        # å¯åŠ¨è®­ç»ƒ
        self.trainer.start_training()
        
        print("\nâœ… ç³»ç»Ÿå·²å¯åŠ¨ï¼")
        print("ğŸ“Š è®¿é—®ä»ªè¡¨æ¿: http://localhost:8766")
        print("ğŸ”§ è®­ç»ƒçŠ¶æ€: å®æ—¶æ›´æ–°ä¸­...")
        
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nğŸ›‘ åœæ­¢ç³»ç»Ÿ...")
            self.trainer.stop_training()

if __name__ == "__main__":
    dashboard = AManagerDashboard()
    dashboard.start()