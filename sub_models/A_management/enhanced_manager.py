# Copyright 2025 The AI Management System Authors
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
å¢å¼ºçš„A_managementæ¨¡å‹ï¼Œç®¡ç†ä¸‹å±æ¨¡å‹çš„æƒ…æ„Ÿåˆ†æåŠŸèƒ½
"""

import torch
import torch.nn as nn
import numpy as np
import json
import os
import time
from datetime import datetime
from collections import deque
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger('A_management')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class ManagementModel(nn.Module):
    """
    å¢å¼ºçš„ç®¡ç†æ¨¡å‹ï¼Œå…·æœ‰ä¸‹å±æ¨¡å‹æƒ…æ„Ÿåˆ†æåŠŸèƒ½ç®¡ç†èƒ½åŠ›
    """
    def __init__(self, config=None):
        """
        åˆå§‹åŒ–ç®¡ç†æ¨¡å‹
        
        å‚æ•°:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«æ¨¡å‹å‚æ•°å’Œä¸‹å±æ¨¡å‹ä¿¡æ¯
        """
        super().__init__()
        
        # é…ç½®é»˜è®¤å€¼
        default_config = {
            'hidden_dim': 512,
            'num_strategies': 10,
            'num_emotions': 7,
            'sub_model_config': {
                'B_language': {'has_emotion_analysis': True, 'emotion_types': ['main', 'sub']},
                'C_audio': {'has_emotion_analysis': True, 'emotion_types': ['main']},
                'D_image': {'has_emotion_analysis': True, 'emotion_types': ['main']},
                'E_video': {'has_emotion_analysis': True, 'emotion_types': ['main', 'intensity']},
                'F_spatial': {'has_emotion_analysis': False},
                'G_sensor': {'has_emotion_analysis': False},
                'I_knowledge': {'has_emotion_analysis': False},
                'J_motion': {'has_emotion_analysis': False},
                'K_programming': {'has_emotion_analysis': False}
            },
            'emotion_weights': {
                'B_language': 0.35,
                'C_audio': 0.25,
                'D_image': 0.20,
                'E_video': 0.20
            },
            'decision_threshold': 0.6
        }
        
        # åˆå¹¶é…ç½®
        self.config = {**default_config, **(config or {})}
        
        # ä¸»ç®¡ç†å±‚
        self.manager_layer = nn.Linear(self.config['hidden_dim'], self.config['hidden_dim'])
        
        # ç­–ç•¥è¾“å‡ºå±‚
        self.strategy_layer = nn.Linear(self.config['hidden_dim'], self.config['num_strategies'])
        
        # æƒ…æ„Ÿåˆ†æè¾“å‡ºå±‚
        self.emotion_layer = nn.Linear(self.config['hidden_dim'], self.config['num_emotions'])
        
        # æ¿€æ´»å‡½æ•°
        self.relu = nn.ReLU()
        self.softmax = nn.Softmax(dim=-1)
        
        # æ¨¡å‹çŠ¶æ€è®°å½•
        self.sub_models = {}
        self.sub_model_status = {}
        self.emotion_history = deque(maxlen=100)
        self.decision_history = deque(maxlen=100)
        
        # åˆå§‹åŒ–æ¨¡å‹çŠ¶æ€
        self.initialize_model_state()
        
    def initialize_model_state(self):
        """
        åˆå§‹åŒ–æ¨¡å‹çŠ¶æ€
        """
        for model_name in self.config['sub_model_config']:
            self.sub_model_status[model_name] = {
                'status': 'inactive',
                'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'performance': {'accuracy': 0.0, 'inference_time': 0.0},
                'emotion_stats': {}
            }
    
    def forward(self, input_features, sub_model_outputs=None):
        """
        å‰å‘ä¼ æ’­ï¼Œå¤„ç†è¾“å…¥å¹¶æ•´åˆä¸‹å±æ¨¡å‹çš„è¾“å‡º
        
        å‚æ•°:
            input_features: è¾“å…¥ç‰¹å¾
            sub_model_outputs: ä¸‹å±æ¨¡å‹çš„è¾“å‡ºå­—å…¸
        
        è¿”å›:
            ç­–ç•¥é¢„æµ‹å’Œæƒ…æ„Ÿé¢„æµ‹
        """
        # å¤„ç†è¾“å…¥ç‰¹å¾
        if isinstance(input_features, dict):
            # å¤„ç†å­—å…¸ç±»å‹è¾“å…¥
            feature_vector = self._process_dict_input(input_features)
        else:
            # å‡è®¾æ˜¯å¼ é‡ç±»å‹è¾“å…¥
            feature_vector = input_features
        
        # ä¸»ç®¡ç†å±‚å¤„ç†
        management_output = self.relu(self.manager_layer(feature_vector))
        
        # ç”Ÿæˆç­–ç•¥é¢„æµ‹
        strategy_logits = self.strategy_layer(management_output)
        strategy_probs = self.softmax(strategy_logits)
        
        # ç”Ÿæˆæƒ…æ„Ÿé¢„æµ‹
        emotion_logits = self.emotion_layer(management_output)
        emotion_probs = self.softmax(emotion_logits)
        
        # å¦‚æœæœ‰ä¸‹å±æ¨¡å‹è¾“å‡ºï¼Œæ•´åˆæƒ…æ„Ÿåˆ†æç»“æœ
        if sub_model_outputs:
            integrated_emotions = self._integrate_sub_model_emotions(sub_model_outputs)
            final_emotion = self._combine_emotions(emotion_probs, integrated_emotions)
            return strategy_probs, final_emotion
        
        return strategy_probs, emotion_probs
    
    def _process_dict_input(self, input_dict):
        """
        å¤„ç†å­—å…¸ç±»å‹çš„è¾“å…¥
        """
        # æå–å¹¶åˆå¹¶å„ç§è¾“å…¥ç‰¹å¾
        feature_list = []
        
        # å¤„ç†æ–‡æœ¬ç‰¹å¾
        if 'text' in input_dict:
            text_feat = torch.tensor(input_dict['text']).to(device) if isinstance(input_dict['text'], list) else input_dict['text']
            if len(text_feat.shape) == 1:
                text_feat = text_feat.unsqueeze(0)
            feature_list.append(text_feat)
        
        # å¤„ç†å…¶ä»–ç±»å‹çš„ç‰¹å¾
        for key, value in input_dict.items():
            if key != 'text' and isinstance(value, (torch.Tensor, list, np.ndarray)):
                if isinstance(value, (list, np.ndarray)):
                    value = torch.tensor(value).to(device)
                if len(value.shape) == 1:
                    value = value.unsqueeze(0)
                feature_list.append(value)
        
        # å¦‚æœæ²¡æœ‰ç‰¹å¾ï¼Œåˆ›å»ºé»˜è®¤ç‰¹å¾
        if not feature_list:
            return torch.zeros(1, self.config['hidden_dim']).to(device)
        
        # åˆå¹¶ç‰¹å¾ï¼ˆè¿™é‡Œç®€å•æ‹¼æ¥ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„ç‰¹å¾èåˆï¼‰
        max_length = max(f.shape[1] for f in feature_list)
        padded_features = []
        
        for feat in feature_list:
            if feat.shape[1] < max_length:
                padding = torch.zeros(feat.shape[0], max_length - feat.shape[1]).to(device)
                padded_feat = torch.cat([feat, padding], dim=1)
            else:
                padded_feat = feat[:, :max_length]
            padded_features.append(padded_feat)
        
        # ç‰¹å¾èåˆ
        combined = torch.cat(padded_features, dim=1)
        
        # è°ƒæ•´åˆ°ç›®æ ‡ç»´åº¦
        if combined.shape[1] != self.config['hidden_dim']:
            proj_layer = nn.Linear(combined.shape[1], self.config['hidden_dim']).to(device)
            combined = proj_layer(combined)
        
        return combined
    
    def _integrate_sub_model_emotions(self, sub_model_outputs):
        """
        æ•´åˆä¸‹å±æ¨¡å‹çš„æƒ…æ„Ÿåˆ†æç»“æœ
        
        å‚æ•°:
            sub_model_outputs: ä¸‹å±æ¨¡å‹çš„è¾“å‡ºå­—å…¸
        
        è¿”å›:
            æ•´åˆåçš„æƒ…æ„Ÿç»“æœ
        """
        integrated = {}
        
        # å®šä¹‰æ ‡å‡†æƒ…ç»ªåˆ—è¡¨ï¼ˆä¸å„æ¨¡å‹ä¿æŒä¸€è‡´ï¼‰
        standard_emotions = ['neutral', 'joy', 'sadness', 'anger', 'fear', 'surprise', 'disgust']
        
        # åˆå§‹åŒ–æ•´åˆæƒ…æ„Ÿå­—å…¸
        for emotion in standard_emotions:
            integrated[emotion] = 0.0
        
        total_weight = 0.0
        
        # éå†ä¸‹å±æ¨¡å‹è¾“å‡º
        for model_name, output in sub_model_outputs.items():
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦é…ç½®äº†æƒ…æ„Ÿåˆ†æåŠŸèƒ½
            if (model_name in self.config['sub_model_config'] and 
                self.config['sub_model_config'][model_name]['has_emotion_analysis']):
                
                # è·å–è¯¥æ¨¡å‹çš„æƒé‡
                weight = self.config['emotion_weights'].get(model_name, 0.1)
                total_weight += weight
                
                # å¤„ç†ä¸åŒæ¨¡å‹çš„æƒ…æ„Ÿè¾“å‡ºæ ¼å¼
                if model_name == 'B_language' and 'emotion_distribution' in output:
                    # å¤„ç†è¯­è¨€æ¨¡å‹çš„æƒ…æ„Ÿåˆ†å¸ƒ
                    for emotion, prob in output['emotion_distribution'].items():
                        if emotion in integrated:
                            integrated[emotion] += prob * weight
                
                elif 'emotion' in output:
                    # å¤„ç†ç®€å•çš„æƒ…æ„Ÿæ ‡ç­¾è¾“å‡º
                    emotion = output['emotion']
                    if emotion in integrated:
                        integrated[emotion] += 1.0 * weight
                
                elif 'emotion_probs' in output:
                    # å¤„ç†æ¦‚ç‡åˆ†å¸ƒè¾“å‡º
                    probs = output['emotion_probs']
                    if isinstance(probs, dict):
                        for emotion, prob in probs.items():
                            if emotion in integrated:
                                integrated[emotion] += prob * weight
                    elif isinstance(probs, (list, np.ndarray, torch.Tensor)):
                        # å‡è®¾é¡ºåºä¸standard_emotionsä¸€è‡´
                        for i, prob in enumerate(probs):
                            if i < len(standard_emotions):
                                emotion = standard_emotions[i]
                                integrated[emotion] += float(prob) * weight
        
        # å½’ä¸€åŒ–æ•´åˆç»“æœ
        if total_weight > 0:
            for emotion in integrated:
                integrated[emotion] /= total_weight
        
        # æ›´æ–°ä¸‹å±æ¨¡å‹çŠ¶æ€
        self._update_sub_model_status(sub_model_outputs)
        
        return integrated
    
    def _combine_emotions(self, own_emotion, integrated_emotions):
        """
        ç»“åˆè‡ªèº«æƒ…æ„Ÿåˆ†æç»“æœå’Œæ•´åˆåçš„ä¸‹å±æ¨¡å‹æƒ…æ„Ÿç»“æœ
        """
        # è½¬æ¢è‡ªèº«æƒ…æ„Ÿç»“æœä¸ºå­—å…¸æ ¼å¼
        standard_emotions = ['neutral', 'joy', 'sadness', 'anger', 'fear', 'surprise', 'disgust']
        own_emotion_dict = {}
        
        for i, emotion in enumerate(standard_emotions):
            if i < len(own_emotion):
                own_emotion_dict[emotion] = float(own_emotion[i])
            else:
                own_emotion_dict[emotion] = 0.0
        
        # ç»“åˆä¸¤ç§æƒ…æ„Ÿç»“æœï¼ˆè¿™é‡Œä½¿ç”¨ç®€å•å¹³å‡ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„ç»“åˆç­–ç•¥ï¼‰
        combined = {}
        for emotion in standard_emotions:
            combined[emotion] = (own_emotion_dict.get(emotion, 0.0) + integrated_emotions.get(emotion, 0.0)) / 2
        
        # å°†ç»“æœè½¬æ¢å›å¼ é‡
        combined_tensor = torch.tensor([combined[emotion] for emotion in standard_emotions]).to(device)
        
        # è®°å½•æƒ…æ„Ÿå†å²
        self.emotion_history.append({
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'own_emotion': own_emotion_dict,
            'integrated_emotions': integrated_emotions,
            'combined_emotion': combined
        })
        
        return combined_tensor
    
    def _update_sub_model_status(self, sub_model_outputs):
        """
        æ›´æ–°ä¸‹å±æ¨¡å‹çš„çŠ¶æ€ä¿¡æ¯
        """
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        for model_name, output in sub_model_outputs.items():
            if model_name in self.sub_model_status:
                # æ›´æ–°åŸºæœ¬çŠ¶æ€
                self.sub_model_status[model_name]['status'] = 'active'
                self.sub_model_status[model_name]['last_update'] = current_time
                
                # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
                if 'accuracy' in output:
                    self.sub_model_status[model_name]['performance']['accuracy'] = float(output['accuracy'])
                if 'processing_time_ms' in output:
                    self.sub_model_status[model_name]['performance']['inference_time'] = float(output['processing_time_ms'])
                
                # æ›´æ–°æƒ…æ„Ÿç»Ÿè®¡
                emotion_stats = self.sub_model_status[model_name]['emotion_stats']
                if 'emotion_distribution' in output:
                    for emotion, prob in output['emotion_distribution'].items():
                        if emotion not in emotion_stats:
                            emotion_stats[emotion] = []
                        emotion_stats[emotion].append(float(prob))
                        # é™åˆ¶å†å²è®°å½•é•¿åº¦
                        if len(emotion_stats[emotion]) > 50:
                            emotion_stats[emotion] = emotion_stats[emotion][-50:]
    
    def register_sub_model(self, model_name, model_instance):
        """
        æ³¨å†Œä¸‹å±æ¨¡å‹
        
        å‚æ•°:
            model_name: æ¨¡å‹åç§°
            model_instance: æ¨¡å‹å®ä¾‹
        """
        self.sub_models[model_name] = model_instance
        logger.info(f"Sub-model {model_name} registered successfully.")
        
        # æ›´æ–°æ¨¡å‹çŠ¶æ€
        if model_name in self.sub_model_status:
            self.sub_model_status[model_name]['status'] = 'active'
            self.sub_model_status[model_name]['last_update'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    def unregister_sub_model(self, model_name):
        """
        æ³¨é”€ä¸‹å±æ¨¡å‹
        
        å‚æ•°:
            model_name: æ¨¡å‹åç§°
        """
        if model_name in self.sub_models:
            del self.sub_models[model_name]
            logger.info(f"Sub-model {model_name} unregistered successfully.")
            
            # æ›´æ–°æ¨¡å‹çŠ¶æ€
            if model_name in self.sub_model_status:
                self.sub_model_status[model_name]['status'] = 'inactive'
                self.sub_model_status[model_name]['last_update'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        else:
            logger.warning(f"Sub-model {model_name} not found.")
    
    def process_task(self, task_input, use_sub_models=True):
        """
        å¤„ç†ä»»åŠ¡ï¼Œå¯é€‰æ˜¯å¦ä½¿ç”¨ä¸‹å±æ¨¡å‹
        
        å‚æ•°:
            task_input: ä»»åŠ¡è¾“å…¥
            use_sub_models: æ˜¯å¦ä½¿ç”¨ä¸‹å±æ¨¡å‹
        
        è¿”å›:
            å¤„ç†ç»“æœ
        """
        start_time = time.time()
        
        # å‡†å¤‡è¾“å…¥ç‰¹å¾
        if isinstance(task_input, str):
            input_features = {'text': task_input}
        else:
            input_features = task_input
        
        # åˆå§‹åŒ–ç»“æœå­—å…¸
        result = {
            'task_type': self._classify_task_type(input_features),
            'manager_decision': None,
            'manager_emotion': None,
            'sub_model_results': {},
            'integrated_result': None
        }
        
        # æ”¶é›†ä¸‹å±æ¨¡å‹çš„è¾“å‡º
        sub_model_outputs = {}
        if use_sub_models:
            sub_model_outputs = self._collect_sub_model_outputs(input_features)
            result['sub_model_results'] = sub_model_outputs
        
        # å‰å‘ä¼ æ’­è·å–ç®¡ç†æ¨¡å‹çš„å†³ç­–å’Œæƒ…æ„Ÿ
        with torch.no_grad():
            strategy_probs, emotion_probs = self.forward(input_features, sub_model_outputs if use_sub_models else None)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„ä¾¿äºå¤„ç†
        if isinstance(strategy_probs, torch.Tensor):
            strategy_probs = strategy_probs.cpu().numpy()
        if isinstance(emotion_probs, torch.Tensor):
            emotion_probs = emotion_probs.cpu().numpy()
        
        # è·å–æœ€é«˜æ¦‚ç‡çš„ç­–ç•¥å’Œæƒ…æ„Ÿ
        best_strategy_idx = np.argmax(strategy_probs)
        
        # å¦‚æœæ˜¯numpyæ•°ç»„ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(strategy_probs, np.ndarray):
            strategy_probs = strategy_probs.tolist()
        if isinstance(emotion_probs, np.ndarray):
            emotion_probs = emotion_probs.tolist()
        
        # è®°å½•å†³ç­–å’Œæƒ…æ„Ÿ
        result['manager_decision'] = {
            'strategy_id': int(best_strategy_idx),
            'confidence': float(strategy_probs[best_strategy_idx]),
            'all_strategies': strategy_probs
        }
        
        # æ„å»ºæƒ…æ„Ÿå­—å…¸
        standard_emotions = ['neutral', 'joy', 'sadness', 'anger', 'fear', 'surprise', 'disgust']
        emotion_dict = {}
        for i, emotion in enumerate(standard_emotions):
            if i < len(emotion_probs):
                emotion_dict[emotion] = float(emotion_probs[i])
        
        result['manager_emotion'] = emotion_dict
        
        # æ•´åˆç»“æœ
        result['integrated_result'] = self._generate_integrated_result(result)
        
        # è®°å½•å†³ç­–å†å²
        self.decision_history.append({
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'task_type': result['task_type'],
            'decision': result['manager_decision'],
            'emotion': result['manager_emotion'],
            'processing_time': (time.time() - start_time) * 1000  # æ¯«ç§’
        })
        
        return result
    
    def _classify_task_type(self, task_input):
        """
        åˆ†ç±»ä»»åŠ¡ç±»å‹
        """
        # åŸºäºè¾“å…¥ç‰¹å¾çš„ç®€å•ä»»åŠ¡ç±»å‹åˆ†ç±»
        if isinstance(task_input, dict):
            if 'text' in task_input and any(key in task_input for key in ['audio', 'image', 'video']):
                return 'multimodal'
            elif 'text' in task_input:
                return 'text'
            elif 'audio' in task_input:
                return 'audio'
            elif 'image' in task_input:
                return 'image'
            elif 'video' in task_input:
                return 'video'
            elif 'sensor' in task_input:
                return 'sensor'
            elif 'spatial' in task_input:
                return 'spatial'
        elif isinstance(task_input, str):
            return 'text'
        
        return 'unknown'
    
    def _collect_sub_model_outputs(self, task_input):
        """
        æ”¶é›†ä¸‹å±æ¨¡å‹çš„è¾“å‡º
        """
        outputs = {}
        task_type = self._classify_task_type(task_input)
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©åˆé€‚çš„ä¸‹å±æ¨¡å‹
        if task_type == 'text' or task_type == 'multimodal':
            if 'B_language' in self.sub_models:
                try:
                    # æå–æ–‡æœ¬éƒ¨åˆ†
                    text_input = task_input['text'] if isinstance(task_input, dict) and 'text' in task_input else str(task_input)
                    lang_output = self.sub_models['B_language'].predict(text_input)
                    outputs['B_language'] = lang_output
                    logger.debug(f"B_language model output collected: {lang_output.get('primary_emotion', 'unknown')}")
                except Exception as e:
                    logger.error(f"Error collecting B_language output: {str(e)}")
        
        # å…¶ä»–æ¨¡å‹è°ƒç”¨é€»è¾‘æ ¹æ®éœ€è¦æ·»åŠ 
        
        return outputs
    
    def _generate_integrated_result(self, partial_result):
        """
        ç”Ÿæˆæ•´åˆç»“æœ
        """
        # è·å–å†³ç­–å’Œæƒ…æ„Ÿ
        decision = partial_result['manager_decision']
        emotion = partial_result['manager_emotion']
        
        # åŸºäºå†³ç­–ç½®ä¿¡åº¦å’Œæƒ…æ„ŸçŠ¶æ€ç”Ÿæˆæ•´åˆç»“æœ
        confidence = decision['confidence']
        primary_emotion = max(emotion, key=emotion.get) if emotion else 'neutral'
        
        # æ ¹æ®ç½®ä¿¡åº¦é˜ˆå€¼å’Œæƒ…æ„Ÿç±»å‹è°ƒæ•´ç»“æœ
        if confidence >= self.config['decision_threshold']:
            result_type = 'high_confidence'
        else:
            result_type = 'low_confidence'
            # ä½ç½®ä¿¡åº¦æ—¶ï¼Œå¯èƒ½éœ€è¦æ›´å¤šä¿¡æ¯æˆ–è°ƒç”¨æ›´å¤šæ¨¡å‹
        
        integrated = {
            'result_type': result_type,
            'confidence_score': confidence,
            'primary_emotion': primary_emotion,
            'emotion_intensity': emotion.get(primary_emotion, 0.0),
            'recommended_action': self._determine_recommended_action(decision, emotion)
        }
        
        return integrated
    
    def _determine_recommended_action(self, decision, emotion):
        """
        åŸºäºå†³ç­–å’Œæƒ…æ„Ÿç¡®å®šæ¨èåŠ¨ä½œ
        """
        strategy_id = decision['strategy_id']
        primary_emotion = max(emotion, key=emotion.get) if emotion else 'neutral'
        emotion_intensity = emotion.get(primary_emotion, 0.0)
        
        # ç®€å•çš„åŠ¨ä½œæ¨èé€»è¾‘ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥æ›´å¤æ‚
        if emotion_intensity > 0.7:
            # é«˜æƒ…æ„Ÿå¼ºåº¦æ—¶çš„åŠ¨ä½œæ¨è
            if primary_emotion in ['joy', 'surprise']:
                return {'type': 'positive_feedback', 'priority': 'high'}
            elif primary_emotion in ['anger', 'fear', 'sadness', 'disgust']:
                return {'type': 'emotion_regulation', 'priority': 'urgent'}
        
        # åŸºäºç­–ç•¥çš„åŠ¨ä½œæ¨è
        if strategy_id % 3 == 0:
            return {'type': 'gather_more_info', 'priority': 'medium'}
        elif strategy_id % 3 == 1:
            return {'type': 'take_action', 'priority': 'high'}
        else:
            return {'type': 'monitor_situation', 'priority': 'low'}
    
    def adjust_response_based_on_emotion(self, response, emotion_context, user_emotion=None):
        """
        æ ¹æ®æƒ…æ„Ÿä¸Šä¸‹æ–‡è°ƒæ•´å“åº”
        
        å‚æ•°:
            response: åŸå§‹å“åº”
            emotion_context: æƒ…æ„Ÿä¸Šä¸‹æ–‡ä¿¡æ¯
            user_emotion: ç”¨æˆ·æƒ…æ„Ÿä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        
        è¿”å›:
            è°ƒæ•´åçš„å“åº”
        """
        if not emotion_context:
            return response
        
        # è·å–ä¸»è¦æƒ…æ„Ÿå’Œå¼ºåº¦
        primary_emotion = max(emotion_context, key=emotion_context.get) if emotion_context else 'neutral'
        emotion_intensity = emotion_context.get(primary_emotion, 0.0)
        
        # æ ¹æ®ä¸åŒæƒ…æ„Ÿå’Œå¼ºåº¦è°ƒæ•´å“åº”
        enhancements = {
            'joy': {
                'prefixes': ['ğŸ˜Š ', 'Great! ', 'Wonderful! '],
                'suffixes': [' ğŸ˜Š', '!', ' :D']
            },
            'sadness': {
                'prefixes': ['ğŸ˜¢ ', 'I\'m sorry to hear that. ', 'That\'s unfortunate. '],
                'suffixes': [' ğŸ˜¢', '.', '...']
            },
            'anger': {
                'prefixes': ['ğŸ˜  ', 'That\'s frustrating. ', 'I understand your frustration. '],
                'suffixes': [' ğŸ˜ ', '.', '!']
            },
            'fear': {
                'prefixes': ['ğŸ˜¨ ', 'I understand your concern. ', 'Let\'s address this carefully. '],
                'suffixes': [' ğŸ˜¨', '.', '...']
            },
            'surprise': {
                'prefixes': ['ğŸ˜² ', 'Wow! ', 'That\'s surprising! '],
                'suffixes': [' ğŸ˜²', '!', '!!']
            },
            'disgust': {
                'prefixes': ['ğŸ˜’ ', 'That\'s unpleasant. ', 'That\'s not ideal. '],
                'suffixes': [' ğŸ˜’', '.', '...']
            }
        }
        
        # å¦‚æœæƒ…æ„Ÿåœ¨å¢å¼ºå­—å…¸ä¸­
        if primary_emotion in enhancements and emotion_intensity > 0.3:
            enh = enhancements[primary_emotion]
            
            # æ ¹æ®æƒ…æ„Ÿå¼ºåº¦é€‰æ‹©å¢å¼ºç¨‹åº¦
            if emotion_intensity > 0.7:
                # é«˜å¼ºåº¦æƒ…æ„Ÿï¼Œä½¿ç”¨å‰ç¼€å’Œåç¼€
                prefix = np.random.choice(enh['prefixes'])
                suffix = np.random.choice(enh['suffixes'])
                adjusted_response = f"{prefix}{response}{suffix}"
            elif emotion_intensity > 0.5:
                # ä¸­ç­‰å¼ºåº¦æƒ…æ„Ÿï¼Œåªä½¿ç”¨å‰ç¼€
                prefix = np.random.choice(enh['prefixes'])
                adjusted_response = f"{prefix}{response}"
            else:
                # ä½å¼ºåº¦æƒ…æ„Ÿï¼Œåªä½¿ç”¨åç¼€
                suffix = np.random.choice(enh['suffixes'])
                adjusted_response = f"{response}{suffix}"
            
            return adjusted_response
        
        # é»˜è®¤ä¸è°ƒæ•´
        return response
    
    def get_sub_model_status(self, model_name=None):
        """
        è·å–ä¸‹å±æ¨¡å‹çš„çŠ¶æ€ä¿¡æ¯
        
        å‚æ•°:
            model_name: å¯é€‰ï¼Œæ¨¡å‹åç§°ï¼Œå¦‚æœä¸æä¾›åˆ™è¿”å›æ‰€æœ‰æ¨¡å‹çš„çŠ¶æ€
        
        è¿”å›:
            æ¨¡å‹çŠ¶æ€ä¿¡æ¯
        """
        if model_name:
            return self.sub_model_status.get(model_name, {})
        else:
            return self.sub_model_status
    
    def get_system_status(self):
        """
        è·å–æ•´ä¸ªç®¡ç†ç³»ç»Ÿçš„çŠ¶æ€ä¿¡æ¯
        """
        # è®¡ç®—æ´»è·ƒæ¨¡å‹æ•°é‡
        active_models = sum(1 for status in self.sub_model_status.values() if status['status'] == 'active')
        total_models = len(self.sub_model_status)
        
        # è®¡ç®—å¹³å‡æ€§èƒ½æŒ‡æ ‡
        avg_accuracy = []
        avg_inference_time = []
        
        for status in self.sub_model_status.values():
            if status['performance']['accuracy'] > 0:
                avg_accuracy.append(status['performance']['accuracy'])
            if status['performance']['inference_time'] > 0:
                avg_inference_time.append(status['performance']['inference_time'])
        
        # è·å–æœ€è¿‘çš„æƒ…æ„Ÿè¶‹åŠ¿
        recent_emotions = []
        for emotion_record in list(self.emotion_history)[-10:]:  # æœ€è¿‘10æ¡è®°å½•
            if 'combined_emotion' in emotion_record:
                recent_emotions.append(emotion_record['combined_emotion'])
        
        # è®¡ç®—æƒ…æ„Ÿè¶‹åŠ¿
        emotion_trend = {}
        if recent_emotions:
            for emotion in recent_emotions[0]:
                values = [record[emotion] for record in recent_emotions]
                emotion_trend[emotion] = {
                    'current': values[-1] if values else 0,
                    'average': np.mean(values) if values else 0,
                    'change': values[-1] - values[0] if len(values) > 1 else 0
                }
        
        status = {
            'system_status': 'healthy' if active_models > 0 else 'warning',
            'active_models': active_models,
            'total_models': total_models,
            'model_status': self.sub_model_status,
            'performance_metrics': {
                'avg_accuracy': np.mean(avg_accuracy) if avg_accuracy else 0,
                'avg_inference_time_ms': np.mean(avg_inference_time) if avg_inference_time else 0
            },
            'emotion_trend': emotion_trend,
            'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        return status
    
    def save_model(self, path):
        """
        ä¿å­˜æ¨¡å‹åˆ°æ–‡ä»¶
        
        å‚æ•°:
            path: ä¿å­˜è·¯å¾„
        """
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(path), exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹çŠ¶æ€å’Œé…ç½®
        torch.save({
            'model_state_dict': self.state_dict(),
            'config': self.config,
            'sub_model_status': self.sub_model_status
        }, path)
        
        logger.info(f"Model saved to {path}")
    
    def load_model(self, path):
        """
        ä»æ–‡ä»¶åŠ è½½æ¨¡å‹
        
        å‚æ•°:
            path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        """
        checkpoint = torch.load(path, map_location=device)
        
        # åŠ è½½æ¨¡å‹çŠ¶æ€å­—å…¸
        self.load_state_dict(checkpoint['model_state_dict'])
        
        # åŠ è½½é…ç½®
        if 'config' in checkpoint:
            self.config.update(checkpoint['config'])
        
        # åŠ è½½ä¸‹å±æ¨¡å‹çŠ¶æ€
        if 'sub_model_status' in checkpoint:
            self.sub_model_status = checkpoint['sub_model_status']
        
        logger.info(f"Model loaded from {path}")
        
        return self

# å·¥å…·å‡½æ•°
def create_management_model(config=None):
    """
    åˆ›å»ºç®¡ç†æ¨¡å‹å®ä¾‹
    
    å‚æ•°:
        config: é…ç½®å­—å…¸
    
    è¿”å›:
        ManagementModelå®ä¾‹
    """
    model = ManagementModel(config)
    
    return model

def generate_management_report(model, report_path):
    """
    ç”Ÿæˆç®¡ç†æŠ¥å‘Š
    
    å‚æ•°:
        model: ManagementModelå®ä¾‹
        report_path: æŠ¥å‘Šä¿å­˜è·¯å¾„
    """
    # è·å–ç³»ç»ŸçŠ¶æ€
    system_status = model.get_system_status()
    
    # è·å–æœ€è¿‘çš„å†³ç­–å†å²
    recent_decisions = list(model.decision_history)[-50:]  # æœ€è¿‘50æ¡å†³ç­–
    
    # å‡†å¤‡æŠ¥å‘Šæ•°æ®
    report = {
        'report_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'system_status': system_status,
        'recent_decisions': recent_decisions,
        'model_config': model.config,
        'summary': {
            'active_models': system_status['active_models'],
            'avg_accuracy': system_status['performance_metrics']['avg_accuracy'],
            'dominant_emotion': max(system_status['emotion_trend'], key=lambda x: system_status['emotion_trend'][x]['current']) if system_status['emotion_trend'] else 'neutral'
        }
    }
    
    # ä¿å­˜æŠ¥å‘Š
    os.makedirs(os.path.dirname(report_path), exist_ok=True)
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    logger.info(f"Management report generated and saved to {report_path}")
    
    return report